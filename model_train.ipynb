{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e024e8a",
   "metadata": {},
   "source": [
    "# FastText Model\n",
    "## Treinamento do modelo\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72106a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "import time\n",
    "import json\n",
    "import fasttext\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c8784de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.read_parquet('train_clean.parquet')\n",
    "with open('variacoes_palavras.json', 'r', encoding='utf-8') as f:\n",
    "    variacoes_palavras = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5418faa0",
   "metadata": {},
   "source": [
    "### Criação da base de conhecimento\n",
    "utilizada as colunas para aprimorar o vocabulário base do fasttext.\\\n",
    "composto das colunas do df + variaçoes criadas por erros de escrita no pre processamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adc25a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fasttext_train.txt', 'w', encoding='utf-8') as f:\n",
    "    for text in df_clean['razaosocial_clean'].dropna():\n",
    "        f.write(text + '\\n')\n",
    "        \n",
    "    for text in df_clean['nome_fantasia_clean'].dropna():\n",
    "        f.write(text + '\\n')\n",
    "    \n",
    "    for text in df_clean['user_input_clean'].dropna():\n",
    "        f.write(text + '\\n')\n",
    "        \n",
    "     # UFs (coluna permitida)\n",
    "    for uf in df_clean['uf'].dropna().unique():\n",
    "        f.write(str(uf) + '\\n')   \n",
    "        \n",
    "    for main_word, variations in variacoes_palavras.items():\n",
    "        for variation in variations:\n",
    "            f.write(variation + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c21be3",
   "metadata": {},
   "source": [
    "função de limpa e padronização um arquivo texto para que ele:\n",
    "\n",
    "1. Não tenha linhas vazias.\n",
    "2. Tenha apenas caracteres ASCII (sem acentos, símbolos ou emojis).\n",
    "3. Tenha uma linha por entrada com texto limpo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb2501f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_file(input_path, output_path):\n",
    "    with open(input_path, 'r', encoding='utf-8', errors='ignore') as f_in:\n",
    "        with open(output_path, 'w', encoding='utf-8') as f_out:\n",
    "            for i, line in enumerate(f_in):\n",
    "                # Verificar linhas problemáticas\n",
    "                if not line.strip():\n",
    "                    continue  # Ignorar linhas vazias\n",
    "                \n",
    "                if any(ord(char) > 127 for char in line):\n",
    "                    # Corrigir caracteres especiais\n",
    "                    line = ''.join(char for char in line if ord(char) < 128)\n",
    "                \n",
    "                f_out.write(line.strip() + '\\n')\n",
    "\n",
    "clean_file('fasttext_train.txt', 'fasttext_train_clean.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a99e20",
   "metadata": {},
   "source": [
    "Foram testados múltiplas configurações para o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aba0067",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_unsupervised(\n",
    "    input='fasttext_train.txt',\n",
    "    model='skipgram',\n",
    "    dim=300,            \n",
    "    epoch=75,           \n",
    "    minCount=2,         \n",
    "    minn=3,             \n",
    "    maxn=5,             \n",
    "    wordNgrams=3,\n",
    "    lr=0.1,            # Taxa de aprendizado\n",
    "    thread=32,         # Utiliza todos os 8 cores 4 threads por core\n",
    "    bucket=5000000,     \n",
    "    loss='hs',         \n",
    "    verbose=2       \n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd9b9a7",
   "metadata": {},
   "source": [
    "### Salvamento do modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15d0f5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('modelo.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e77193",
   "metadata": {},
   "source": [
    "## Avaliação do\n",
    "### Teste da acurácia do modelo\n",
    "Encontrar palavras utilizando a tecnica de nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48814dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avaliando modelo:  24%|██▍       | 164657/690695 [14:59<47:54, 182.98it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Timeout atingido após 15 minutos\n",
      "Acurácia: 77.11% | Testes realizados: 164658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def evaluate_model(model, test_cases, timeout_minutes=30):\n",
    "    acertos = 0\n",
    "    total_testes = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Criar lista plana de testes\n",
    "    test_list = []\n",
    "    for palavra, variacoes in test_cases.items():\n",
    "        for variacao in variacoes:\n",
    "            test_list.append((palavra, variacao))\n",
    "    \n",
    "    # Avaliar com barra de progresso\n",
    "    for palavra, variacao in tqdm(test_list, desc=\"Avaliando modelo\"):\n",
    "        try:\n",
    "            similares = model.get_nearest_neighbors(variacao, k=5)\n",
    "            palavras_similares = [p for _, p in similares]\n",
    "            \n",
    "            if palavra in palavras_similares:\n",
    "                acertos += 1\n",
    "                \n",
    "            total_testes += 1\n",
    "            \n",
    "            # Verificar timeout\n",
    "            elapsed = (time.time() - start_time) / 60\n",
    "            if elapsed > timeout_minutes:\n",
    "                print(f\"\\nTimeout atingido após {timeout_minutes} minutos\")\n",
    "                break\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"\\nErro ao processar '{variacao}': {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Retornar ambos os valores\n",
    "    acuracia = acertos / total_testes if total_testes > 0 else 0.0\n",
    "    return acuracia, total_testes\n",
    "\n",
    "acuracia, total_testes = evaluate_model(model, variacoes_palavras, timeout_minutes=15)\n",
    "print(f\"Acurácia: {acuracia:.2%} | Testes realizados: {total_testes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d007e21b",
   "metadata": {},
   "source": [
    "#### Criação de chave única por empresa\n",
    "composta de razao_social + nome fantasia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543ccb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de empresas únicas: 9905\n"
     ]
    }
   ],
   "source": [
    "# Criação do dicionário de empresas únicas\n",
    "empresas_embeddings = []\n",
    "chaves_unicas = set()\n",
    "\n",
    "for _, row in df_clean.iterrows():\n",
    "    razao = row['razaosocial_clean'] or \"\"\n",
    "    fantasia = row['nome_fantasia_clean'] or \"\"\n",
    "    chave = f\"{razao}|{fantasia}\"\n",
    "    \n",
    "    # Se já processamos essa combinação, pular\n",
    "    if chave in chaves_unicas:\n",
    "        continue\n",
    "        \n",
    "    chaves_unicas.add(chave)\n",
    "    \n",
    "    texto_empresa = f\"{razao} {fantasia}\".strip()\n",
    "    palavras = texto_empresa.split()\n",
    "    vetores = []\n",
    "    \n",
    "    for p in palavras:\n",
    "        if p in model.words:\n",
    "            vetores.append(model.get_word_vector(p))\n",
    "    \n",
    "    # Calcular embedding médio\n",
    "    if vetores:\n",
    "        embedding_medio = np.mean(vetores, axis=0)\n",
    "    else:\n",
    "        embedding_medio = np.zeros(model.get_dimension())\n",
    "    \n",
    "    empresas_embeddings.append({\n",
    "        'razao_social': razao,\n",
    "        'nome_fantasia': fantasia,\n",
    "        'embedding': embedding_medio\n",
    "    })\n",
    "\n",
    "print(f\"Total de empresas únicas: {len(empresas_embeddings)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850be6e7",
   "metadata": {},
   "source": [
    "#### Buscar empresas mais similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3055ee21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def buscar_empresas(query, top_n=5):\n",
    "    # Pré-processar a query\n",
    "    palavras = query.lower().split()\n",
    "    vetores = []\n",
    "    \n",
    "    # Obter vetores para palavras válidas\n",
    "    for p in palavras:\n",
    "        if p in model.words:\n",
    "            vetores.append(model.get_word_vector(p))\n",
    "    \n",
    "    if not vetores:\n",
    "        return []\n",
    "    \n",
    "    # Calcular embedding médio da query\n",
    "    query_embed = np.mean(vetores, axis=0)\n",
    "    \n",
    "    # Normalização CRUCIAL para similaridade correta\n",
    "    norm_query = np.linalg.norm(query_embed)\n",
    "    if norm_query == 0:\n",
    "        return []\n",
    "    query_embed_norm = query_embed / norm_query\n",
    "    \n",
    "    resultados = []\n",
    "    empresas_vistas = set()\n",
    "    \n",
    "    # Calcular similaridade para cada empresa\n",
    "    for empresa in empresas_embeddings:\n",
    "        # Criar chave única para evitar duplicatas\n",
    "        chave = f\"{empresa['razao_social']}|{empresa['nome_fantasia']}\"\n",
    "        if chave in empresas_vistas:\n",
    "            continue\n",
    "        empresas_vistas.add(chave)\n",
    "        \n",
    "        emb = empresa['embedding']\n",
    "        norm_emb = np.linalg.norm(emb)\n",
    "        \n",
    "        # Ignorar empresas com embedding zerado\n",
    "        if norm_emb == 0:\n",
    "            continue\n",
    "            \n",
    "        # Calcular similaridade de cosseno\n",
    "        emb_norm = emb / norm_emb\n",
    "        sim = np.dot(emb_norm, query_embed_norm)\n",
    "        \n",
    "        resultados.append({\n",
    "            'razao_social': empresa['razao_social'],\n",
    "            'nome_fantasia': empresa['nome_fantasia'],\n",
    "            'similaridade': sim  # Agora entre -1 e 1\n",
    "        })\n",
    "    \n",
    "    # Ordenar resultados por similaridade decrescente\n",
    "    resultados_ordenados = sorted(resultados, key=lambda x: x['similaridade'], reverse=True)\n",
    "    return resultados_ordenados[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "796d7e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testar_busca(query, top_n=5):\n",
    "    print(f\"\\n--- Testando: '{query}' ---\")\n",
    "    palavras_validas = [p for p in query.split() if p in model.words]\n",
    "    print(f\"Palavras válidas no modelo: {palavras_validas}\")\n",
    "    \n",
    "    resultados = buscar_empresas(query, top_n)\n",
    "    \n",
    "    if not resultados:\n",
    "        print(\"Nenhum resultado encontrado\")\n",
    "        return\n",
    "        \n",
    "    for i, res in enumerate(resultados, 1):\n",
    "        print(f\"{i}. {res['nome_fantasia']} | Similaridade: {res['similaridade']:.4f}\")\n",
    "        \n",
    "        # Mostrar razão social apenas se for diferente do nome fantasia\n",
    "        if res['razao_social'] and res['razao_social'] != res['nome_fantasia']:\n",
    "            print(f\"   Razão Social: {res['razao_social']}\")\n",
    "    \n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33197fe",
   "metadata": {},
   "source": [
    "##### Teste da capacidade de busca do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b06b46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testando: 'magazine luiz' ---\n",
      "Palavras válidas no modelo: ['magazine', 'luiz']\n",
      "1. magazine luzia | Similaridade: 0.7686\n",
      "   Razão Social: magazine luiza\n",
      "2. magazine luiza | Similaridade: 0.7506\n",
      "3. magazineluiza | Similaridade: 0.7438\n",
      "   Razão Social: magazine luiza\n",
      "4. imperio magazine | Similaridade: 0.6032\n",
      "5. sol magazine | Similaridade: 0.6004\n",
      "   Razão Social: sol magazine uruacu\n",
      "\n",
      "--- Testando: 'posto guerra' ---\n",
      "Palavras válidas no modelo: ['posto', 'guerra']\n",
      "1. posto luiz guerra | Similaridade: 0.8833\n",
      "   Razão Social: auto posto luiz guerra\n",
      "2. galvao guerra | Similaridade: 0.7181\n",
      "3. auto posto wr | Similaridade: 0.6283\n",
      "4. auto posto marciano | Similaridade: 0.6278\n",
      "5. auto posto formigao | Similaridade: 0.6100\n",
      "\n",
      "--- Testando: 'farmaceutica' ---\n",
      "Palavras válidas no modelo: ['farmaceutica']\n",
      "1. inovat | Similaridade: 0.6121\n",
      "   Razão Social: uniao quimica farmaceutica\n",
      "2. drogal brodowski | Similaridade: 0.5853\n",
      "   Razão Social: drogal farmaceutica\n",
      "3. rd farma | Similaridade: 0.5752\n",
      "   Razão Social: rede de logistica farmaceutica dinamica\n",
      "4. drogal cabreuva | Similaridade: 0.5714\n",
      "   Razão Social: drogal farmaceutica\n",
      "5. drogal cravinhos | Similaridade: 0.5687\n",
      "   Razão Social: drogal farmaceutica\n"
     ]
    }
   ],
   "source": [
    "testes = [\"magazine luiz\", \"posto guerra\", \"farmaceutica\"]\n",
    "for query in testes:\n",
    "    testar_busca(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88aa7ce5",
   "metadata": {},
   "source": [
    "### Classificação do Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed8791b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pré-calculando embeddings para empresas únicas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9905/9905 [00:02<00:00, 4010.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pré-calculando embeddings para queries únicas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78702/78702 [00:08<00:00, 9402.72it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando matrizes para cálculo vetorizado...\n",
      "Calculando matriz de similaridade completa...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:10<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando avaliação completa do DataFrame...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 255471/255471 [02:49<00:00, 1505.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Resultados da Avaliação Completa (Total de registros válidos: 255392)\n",
      "Top-1 Accuracy: 0.4931 (125934/255392)\n",
      "Top-5 Accuracy: 0.7535 (192441/255392)\n",
      "============================================================\n",
      "Resultados salvos em 'resultados_avaliacao.txt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Pré-calcular embeddings para todas as empresas únicas\n",
    "print(\"Pré-calculando embeddings para empresas únicas...\")\n",
    "empresas_unicas = df_clean[['razaosocial_clean', 'nome_fantasia_clean']].drop_duplicates()\n",
    "\n",
    "# Dicionário para embeddings das empresas\n",
    "emp_embeddings = {}\n",
    "for _, row in tqdm(empresas_unicas.iterrows(), total=len(empresas_unicas)):\n",
    "    razao = row['razaosocial_clean'] or \"\"\n",
    "    fantasia = row['nome_fantasia_clean'] or \"\"\n",
    "    texto = f\"{razao} {fantasia}\".strip()\n",
    "    palavras = texto.split()\n",
    "    vetores = [model.get_word_vector(p) for p in palavras if p in model.words]\n",
    "    \n",
    "    if vetores:\n",
    "        embedding = np.mean(vetores, axis=0)\n",
    "    else:\n",
    "        embedding = np.zeros(model.get_dimension())\n",
    "    \n",
    "    emp_embeddings[(razao, fantasia)] = embedding\n",
    "\n",
    "# Pré-calcular embeddings para todas as queries únicas\n",
    "print(\"Pré-calculando embeddings para queries únicas...\")\n",
    "queries_unicas = df_clean['user_input_clean'].dropna().unique()\n",
    "query_embeddings = {}\n",
    "for query in tqdm(queries_unicas):\n",
    "    palavras = query.split()\n",
    "    vetores = [model.get_word_vector(p) for p in palavras if p in model.words]\n",
    "    \n",
    "    if vetores:\n",
    "        embedding = np.mean(vetores, axis=0)\n",
    "    else:\n",
    "        embedding = np.zeros(model.get_dimension())\n",
    "    \n",
    "    query_embeddings[query] = embedding\n",
    "\n",
    "# Criar matriz de embeddings para cálculo eficiente\n",
    "print(\"Preparando matrizes para cálculo vetorizado...\")\n",
    "# Converter para arrays numpy\n",
    "all_emp_keys = list(emp_embeddings.keys())\n",
    "emp_matrix = np.array([emp_embeddings[k] for k in all_emp_keys])\n",
    "\n",
    "all_query_keys = list(query_embeddings.keys())\n",
    "query_matrix = np.array([query_embeddings[k] for k in all_query_keys])\n",
    "\n",
    "# Normalizar embeddings para similaridade de cosseno eficiente\n",
    "emp_norms = np.linalg.norm(emp_matrix, axis=1, keepdims=True)\n",
    "emp_norms[emp_norms == 0] = 1e-9  # Evitar divisão por zero\n",
    "emp_matrix_norm = emp_matrix / emp_norms\n",
    "\n",
    "query_norms = np.linalg.norm(query_matrix, axis=1, keepdims=True)\n",
    "query_norms[query_norms == 0] = 1e-9\n",
    "query_matrix_norm = query_matrix / query_norms\n",
    "\n",
    "# Calcular matriz de similaridade em blocos (para economizar memória)\n",
    "def calcular_similaridades_em_blocos(query_matrix, emp_matrix, block_size=1000):\n",
    "    \"\"\"Calcula similaridades em blocos para evitar estouro de memória\"\"\"\n",
    "    num_queries = query_matrix.shape[0]\n",
    "    similarity_matrix = np.zeros((num_queries, emp_matrix.shape[0]))\n",
    "    \n",
    "    for start in tqdm(range(0, num_queries, block_size)):\n",
    "        end = min(start + block_size, num_queries)\n",
    "        block = query_matrix[start:end]\n",
    "        sim_block = np.dot(block, emp_matrix.T)\n",
    "        similarity_matrix[start:end] = sim_block\n",
    "    \n",
    "    return similarity_matrix\n",
    "\n",
    "print(\"Calculando matriz de similaridade completa...\")\n",
    "similarity_matrix = calcular_similaridades_em_blocos(query_matrix_norm, emp_matrix_norm)\n",
    "\n",
    "# Mapear índices para busca rápida\n",
    "query_idx_map = {query: idx for idx, query in enumerate(all_query_keys)}\n",
    "emp_idx_map = {emp: idx for idx, emp in enumerate(all_emp_keys)}\n",
    "\n",
    "# Função para avaliar todo o DataFrame\n",
    "def avaliar_dataframe_completo(df):\n",
    "    top1_correct = 0\n",
    "    top5_correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        query = row['user_input_clean']\n",
    "        razao_esperada = row['razaosocial_clean']\n",
    "        fantasia_esperada = row['nome_fantasia_clean']\n",
    "        emp_esperada = (razao_esperada, fantasia_esperada)\n",
    "        \n",
    "        # Pular linhas sem query válida\n",
    "        if pd.isna(query) or not query:\n",
    "            continue\n",
    "        \n",
    "        # Obter índices\n",
    "        query_idx = query_idx_map.get(query)\n",
    "        emp_idx = emp_idx_map.get(emp_esperada)\n",
    "        \n",
    "        # Se não encontrou algum dos embeddings, pular\n",
    "        if query_idx is None or emp_idx is None:\n",
    "            continue\n",
    "        \n",
    "        # Obter similaridades para esta query\n",
    "        query_similarities = similarity_matrix[query_idx]\n",
    "        \n",
    "        # Encontrar top 5 empresas para esta query\n",
    "        top5_indices = np.argsort(query_similarities)[::-1][:5]\n",
    "        \n",
    "        # Verificar se a empresa esperada está no top 1 e top 5\n",
    "        if top5_indices[0] == emp_idx:\n",
    "            top1_correct += 1\n",
    "            top5_correct += 1\n",
    "        elif emp_idx in top5_indices:\n",
    "            top5_correct += 1\n",
    "        \n",
    "        total += 1\n",
    "    \n",
    "    return top1_correct, top5_correct, total\n",
    "\n",
    "# Executar avaliação completa\n",
    "print(\"\\nIniciando avaliação completa do DataFrame...\")\n",
    "top1_correct, top5_correct, total_valid = avaliar_dataframe_completo(df_clean)\n",
    "\n",
    "# Calcular métricas finais\n",
    "top1_accuracy = top1_correct / total_valid if total_valid > 0 else 0\n",
    "top5_accuracy = top5_correct / total_valid if total_valid > 0 else 0\n",
    "\n",
    "# Resultados finais\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"Resultados da Avaliação Completa (Total de registros válidos: {total_valid})\")\n",
    "print(f\"Top-1 Accuracy: {top1_accuracy:.4f} ({top1_correct}/{total_valid})\")\n",
    "print(f\"Top-5 Accuracy: {top5_accuracy:.4f} ({top5_correct}/{total_valid})\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
